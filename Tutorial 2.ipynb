{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Autograd Differentiation**"
      ],
      "metadata": {
        "id": "TxEukokNCwwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autograd differentiation in PyTorch is PyTorchâ€™s automatic differentiation engine. It automatically computes gradients (derivatives) of tensors, which is essential for training neural networks during backpropagation"
      ],
      "metadata": {
        "id": "Vg6suApyKY5D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uSCisPqT00vi"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1)**"
      ],
      "metadata": {
        "id": "ix1O6_bhIcwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(5.0, requires_grad = True)\n",
        "y = x ** 2\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYDD8_LBG9dN",
        "outputId": "7d7f7e97-64ef-4e11-b0d2-a51eea14c394"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5., requires_grad=True)\n",
            "tensor(25., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all the derivatives in the backward direction is calculated\n",
        "y.backward()"
      ],
      "metadata": {
        "id": "L9-FGKuMHaPr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to see grad value\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPpyyhIiH_5Z",
        "outputId": "e8b5195f-9d94-4e26-a622-900243bfd707"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2)**"
      ],
      "metadata": {
        "id": "jBXiVdetIiI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.tensor(4.0, requires_grad= True)\n",
        "y2 = x2 ** 2\n",
        "z2 = torch.sin(y2)\n",
        "\n",
        "print(x2)\n",
        "print(y2)\n",
        "print(z2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7mitB6OIDfJ",
        "outputId": "5b3f55c8-b6dd-42d2-b407-7be024f94c69"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4., requires_grad=True)\n",
            "tensor(16., grad_fn=<PowBackward0>)\n",
            "tensor(-0.2879, grad_fn=<SinBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2.backward()"
      ],
      "metadata": {
        "id": "500D6l9OI7j7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxUejYbuJKB4",
        "outputId": "3ecc5f57-3055-4db5-f654-21b9372219a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-7.6613)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPjdJiXEJpjo",
        "outputId": "645d7d7a-89d1-4c52-946c-98d7051be7cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3489126098.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  y2.grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3)**"
      ],
      "metadata": {
        "id": "ILLQDWmzK80b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network"
      ],
      "metadata": {
        "id": "zY3s_M7yLD3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = torch.tensor(6.7)\n",
        "y3 = torch.tensor(0.0)"
      ],
      "metadata": {
        "id": "lsw-3LfJJ6m4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCsCmcJWMiz1",
        "outputId": "9c52b7ca-66a3-40e4-859e-85937f2b62a9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., requires_grad=True)\n",
            "tensor(0., requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = w*x3 + b\n",
        "y_pred = torch.sigmoid(z)\n",
        "print(z)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy3cvqRtMxyU",
        "outputId": "18cbc602-2347-4c4d-d6ba-4857f64e8cc8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.7000, grad_fn=<AddBackward0>)\n",
            "tensor(0.9988, grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(y_pred, y_true):\n",
        "  # to prevent log(0)\n",
        "  e = 1e-8\n",
        "\n",
        "  # clamp func. restricts values of a tensor to a given range\n",
        "  y_pred = torch.clamp(y_pred, e, 1-e)\n",
        "\n",
        "  return -(y_true*torch.log(y_pred) + (1-y_true)*torch.log(1-y_pred))"
      ],
      "metadata": {
        "id": "af5dXo4ENLHW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(y_pred, y3)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj5DWJMiObiE",
        "outputId": "61187de9-420a-47d8-be82-04ebbc48776d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.7012, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "LgoADMCtOhZE"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGdbCRwyPBBD",
        "outputId": "f915b7e0-9e41-45b6-efe8-51d2706a5d74"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6918)\n",
            "tensor(0.9988)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 4)**"
      ],
      "metadata": {
        "id": "aifY45krTQsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector"
      ],
      "metadata": {
        "id": "zSycm_u9T5eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 3.0, 4.0], requires_grad=True)\n",
        "print(x.shape)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0V0chzePCYS",
        "outputId": "0e946370-a58e-4b05-c90b-608f5301fdc2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "tensor([1., 3., 4.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = (x**2).mean()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_TnaTH8TjTQ",
        "outputId": "8d584761-e8d5-4b8d-fcde-fd577fefd05a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.6667, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "zMKRq_BmTnnu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNGlpJuNTzFe",
        "outputId": "7a121053-37c6-41bf-83de-6f830e78b78a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6667, 2.0000, 2.6667])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clearing Gradients"
      ],
      "metadata": {
        "id": "j4Sd-NOWUYDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9XJcFLcT0Ce",
        "outputId": "2ba0e97b-626e-4f52-fdc8-fe372b18aa07"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icmcIUblUkN9",
        "outputId": "b23d6c8b-4537-445e-cf7d-c6855e2a5bbe"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE6tOibzUp-O",
        "outputId": "1a91d210-e8d5-4993-e7f7-fb36205a82d0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHIZEQhhUs2u",
        "outputId": "e44973ec-081b-40dc-af56-8cff975d4b25"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1AHTx5dUvkd",
        "outputId": "b52a69e1-8b07-4702-ee30-653e49e606ca"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, gradients are accumulated because they are not cleared automatically. Each call to backward() adds the newly computed gradients to the existing gradients"
      ],
      "metadata": {
        "id": "lo3jWEsCU-H2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradients must be explicitly cleared before each backward pass using grad.zero_()."
      ],
      "metadata": {
        "id": "Fss1-_DhVvAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTdLPGnKUy3t",
        "outputId": "797f581f-ad00-4321-8f88-74bfb2b2f225"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsSNlCAcV9UN",
        "outputId": "e0b10ac8-4cad-496d-ef23-8dfa93d5e304"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disable gradient tracking"
      ],
      "metadata": {
        "id": "HIgvz8qaWF5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We disable gradient tracking to save memory and speed up computation when gradients are not needed.\n",
        "It is used during inference, validation, and testing, where we only do forward passes."
      ],
      "metadata": {
        "id": "oGUg6Fh-XrhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCQ8YVvxWByL",
        "outputId": "d4058c42-606b-4395-f18c-6d3a211ae264"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kRtHNS9WVrN",
        "outputId": "89cc0466-331d-4aab-b78c-dd20ad042565"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 1) Using require_grad"
      ],
      "metadata": {
        "id": "MT1sVnOdWao6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAz_ZGsZWXpN",
        "outputId": "b817cf8c-53e5-495e-ffd1-57effede0496"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 2) Using detach"
      ],
      "metadata": {
        "id": "ZyP9RiN1WsvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = x.detach()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR60FRdLWp5O",
        "outputId": "5e69632e-1c96-4538-ccae-859241482f78"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY_5VlWwW13L",
        "outputId": "ba2c3824-1090-4b27-98c1-0faadf658484"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = z**2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x9syj2mW6U8",
        "outputId": "0eb5bbd8-c54f-4fd0-a849-a56e857a9a77"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 3) Using no_grad"
      ],
      "metadata": {
        "id": "aKwYTvMdXAyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = x**2"
      ],
      "metadata": {
        "id": "zPJecsbdW-6c"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eduRCqLLXPqL",
        "outputId": "0607718c-6215-446a-da2a-aab2f7fc037c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ]
}